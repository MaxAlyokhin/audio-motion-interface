### Audio Motion Interface (AMI)

##### Sonification interface for motion and orientation

Демо здесь (заходить со смартфона): https://ami.fly.dev

Система синтезирует звук на основе данных с датчиков движения смартфона: скорость (акселерометр) определяет громкость, положение (гироскоп) определяет частоту.

TODO: Видео демонстрация:

Предусмотрен т.н. локальный режим (когда смартфон просто проводом подключается к колонкам/комбику или наушникам, либо подключается к bluetooth-колонкам) и удалённый режим (когда смартфон и колонки разнесены в пространстве, а данные идут по протоколу <a href="https://ru.wikipedia.org/wiki/WebSocket">websocket</a> через промежуточный сервер).

Система имеет минимальное количество внутренних настроек, оставляя на ваше усмотрение возможность его обработки (это могут быть как педали/примочки, так и разнообразные DAW вроде Ableton, Cubase, FL Studio и т.д.)

#### Кратко как использовать

Note: Firefox не поддерживается, Safari под вопросом.

Самый простой вариант - зайти со смартфона на https://ami.fly.dev. Смартфон попросит доступ к датчикам - его необходимо разрешить. После этого он сразу начнёт генерировать звук при лёгком встряхивании из встроенного динамика. Здесь лучше либо подключить наушники, либо подключиться к bluetooth-колонке, либо кабелем миниджек-миниджек (или с помощью переходника на джек) соединить с колонками/усилителем/комбиком. При таком варианте есть следующие недостатки:

- вы связаны кабелем
- у смартфона есть ощутимая задержка
- вы не видите что играете (генерируемую ноту/частоту)
- не очень удобно изменять настройки

Все эти недостатки решаются распределённым режимом работы. Для этого:

- зайти дополнительно с компа на https://ami.fly.dev. На компе автоматически включится специальный режим приёмника данных. При этом отобразится строка "Подключено (1)" (цифра может быть больше, если кто-то ещё зашёл на сайт вместе с вами).
- на смартфоне переключить стратегию синтеза на распределённый режим
- теперь смартфон передаёт данные о движении на ноутбук. Здесь и смартфон, и компьютер начинают синтезировать звук. Смартфон справляется с этой задачей с большей задержкой, из-за чего при включённом звуке на обоих устройствах можно услышать что-то вроде эха. Здесь можно убавить громкость на смартфоне до нуля, а ноутбук подключить к вашей аудио-системе.

Из ноутбука, соответственно, можно звук передать в DAW через Virtual Audio Cabel и обработать там, пустив на вход VAC звуки операционной системы (так как браузер отдаёт звук туда), а выход VAC подключить к DAW. Тогда звук можно снимать либо с миниджека компьютера, либо с внешнего-аудиоинтерфейса, а оттуда обрабатывать дальше.

Итого некоторые возможные схемы работы:
- смартфон → встроенный динамик
- смартфон → наушники
- смартфон → bluetooth → колонка
- смартфон → миниджек → колонки
- смартфон → миниджек → DAW на компьютере → миниджек → колонки
- смартфон → миниджек → педали/примочки → джек → колонки
- смартфон → websocket → компьютер → DAW → миниджек → педали/примочки → джек → колонки

Note: использование https://ami.fly.dev - демонстрационный вариант. Главный его недостаток это синхронизация между всеми пользователями; ваш звук и ваши настройки могут перебить случайные пользователи. Плюс, так как информация о движении идёт через интернет, может наблюдаться задержка (порядка 20мс, в зависимости от качества связи). Для решения всех этих недостатков рекомендуется развернуть систему локально (смотри раздел "Запуск релиз-версии").

#### User guide

- при открытии с десктопа автоматически включается режим приёмника данных. Это означает, что компьютер готов принимать данные от внешних смартфонов;
- при открытии со смартфона

звук генерится и на смартофне и на компе, на компе задержка меньше

#### Теория и термины

##### Стратегия синтеза

Что имеется в виду

##### Локальный режим:

<i>Источник данных</i> и <i>управление данными</i> находятся на смартфоне (совмещены).

##### Удалённый режим:

<i>Источник данных</i> находится на смартфоне, а <i>управление данными</i> находится на удалённой машине (разнесены).

- смартфон → вебсокет → браузер → миниджек → колонки
- смартфон → вебсокет → браузер → аблетон → миниджек → колонки

Плюсы:

- смартфон не связан проводом с ноутбуком;
- разделение источника данных от управления данными - ноутбук лучше справится с обработкой данных;

Минусы:

- исполнителю не слышно ничего (можно одновременно генерить звук локально со смартфона в наушники и дополнительно дублировать данные движения на удалённую машину; по идее, тогда любой может подключиться к прослушиванию исполнения и можно сделать распределённое удалённое прослушивание откуда угодно; но тогда удалённые слушателя останутся без обработки ableton, только обработка с сервера);
- есть задержка до 100мс;

##### Граф
Это связка осциллятор => фильтр => громкость

##### Событие движения
js-событие, генерируемое каждые 16мс смартфоном, содержащее параметры движения. События возникают даже в состоянии покоя - в этом случае параметры движения нулевые.

##### Отсечка
Минимальная скорость движения, при которой заводится система.

##### Жест
Набор событий движения от превышения отсечки до значения ниже отсечки. Каждому жесту соответствует свой осциллятор.

#### Идеи по нетривиальному использованию

1. Скинуть с вертолёта с записью нот и живой игрой по этим нотам (Импровизация для падающего смартфона / Композиция для падающего смартфона)
2. Очень долгая игра (супер мелкое движение порождает эхо длиной на год), снять под это отдельное помещение с ежедневным доступом и его трансляцией в интернет. Написать партитуру в виде толстой папки, чтобы иметь возможность воспроизвести это один-в-один
3. Оркестр смартфонов

#### Запуск

##### Запуск демо-версии

В локальном режиме:
1. Зайти на https://ami.fly.dev со смартфона

Note: в локальном режиме задержка синтеза звука может быть довольно ощутима в связи с тем, что вычислительный ресурс у смартфона довольно ограничен по сравнению с даже самым средним ноутбуком.

В распределённом режиме:
1. Зайти на https://ami.fly.dev с компа
2. Зайти на https://ami.fly.dev со смартфона

Note: в распределённом режиме синтез звука становится общим для всех кто зашёл в данным момент на сайт, а настройки синхронизироются между всеми пользователями. То есть, если на сайт зашло несколько человек одновременно и кто-то поменял настройки синтеза, они поменяются у всех участников; звуки, генерируемые одним участником, воспроизведутся на всех устройстах всех посетителей.

##### Запуск релиз-версии (запуск на локальном компьютере)

Релиз версия содержит:
- index.js
- /node_modules
- client/dist

1. Ставим Node.js
2. Скачиваем AMI
3. Генерим SSL-сертификаты с именами localhost+2.pem и localhost+2-key.pem
4. Запускаем cmd.exe
5. node index
6. Открываем ссылку из терминала на компе
7. Открываем ссылку из терминала на смартфоне

Note: смартфон и компьютер должны быть подключены к одной wifi-сети. Либо можно запустить виртуальный роутер на ноутбуке (с помощью стороннего сервиса а-ля Connectify) и подключить смартфон к ноутбуку.

Note: время задержки в таком варианте запуска самое минимальное из возможных.

TODO: сделать эту релиз-версию и где-то выложить
TODO: можно автоматизировать через shell-скрипт (можно ли поставить ноду в тихом режиме?)
TODO: можно попробовать Electron

##### Запуск development-версии

При желании доработать или переработать код, нужно запустить необходимое окружение разработки.

Первый запуск

1. `git clone`
2. `npm i`
3. Генерация ssl-сертификата
https://stackoverflow.com/questions/21397809/create-a-trusted-self-signed-ssl-cert-for-localhost-for-use-with-express-node
4. `nodemon index` (или просто `node index`)
5. Открываем второй терминал
6. `cd client`
7. `npm i`
8. `gulp`

Последующие запуски:
1. В первом терминале: `nodemon index` (или просто `node index`)
2. Во втором терминале: `cd client`
3. `gulp`

Первый терминал это бэкенд, второй терминал это фронтенд.

На компе и смартфоне открываем ссылку из первого терминала.

Включаем распределённую стратегию синтеза.

Note: в целях разработки лучше глобалньо установить Nodemon. Тогда за перезапуск при измененях кода в бэкенде будет отвечать он, а за изменения в коде фронтенда будет отвечать Gulp.

##### Туннелирование локального сервера

Локальный сервер можно расшарить в интернет с помощью туннелирования, например, с сервисом ngrok:

`ngrok http https://localhost`

На компе открываем https://localhost

На смартфоне сгенеренную ngrok ссылку на туннель.

#### Tech guide

##### Общая архитектура

Стек: ...

Структура папок: ...

Аудио граф:
...

Общий принцип работы
по событию движения смотрим отсечку, если превысили запускает то-то создаём связку, если после этого оказались ниже отсечки, то делаем то-то планируем удаление связки.
Объект настроек...

У нас есть массив осцилляторов (вернее массивы элементов-узлов графа). При превышении отсечки мы можем сказать, что движение началось. При скорости ниже отсечки мы можем сказать, что движение закончилось, отследив что это последнее событие движения в череде событий с помощью маркера `motionIsOff`.

##### Более детальный обзор
Бэкенд:
express socket.io ...

Фронтенд:
- сборка:
собирает Gulp, конфиг тут, делает то-то, кладёт в dist, который сервит Express.

- описание основных функций:
`motion.js` занимается датчиками - акселерометром и гироскопом.
Он вешает слушатели событий движения и вызывает `audio.js` по каждому событию

`audio.js` принимает данные о движении и генерирует звук

#### Bags and features

- TODO: создать нормальную документацию по разработке
- TODO: создать юзер гайд по инструменту с видео, гайд по развёртке с ноутом (по сути надо будет поставить ноду и запустить index.js с серверами, gulp и исходники фронта не нужны. Только нужно преодолеть https-сертификаты)
- TODO: режим записи нот (для трюка с импровизацией/композицией для падающего смартфона). по каждому событию движения частота переводится в ноту и затем проверяется режим записи из сеттингс - если вкл, то иннертекстим ноту на экран. далее можно допилить рисовку на нотном стане и даже отдельный фронтэнд для только партитуры
- TODO: перевести на английский
